---
title       : Diferencias de Medias
subtitle    : Dos medias y $k$ medias, con supuestos.
author      : Valentín Vergara Hidd
job         : Uso de Software en Investigación Social
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : tomorrow      # 
widgets     : [mathjax, quiz, bootstrap]            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
knit        : slidify::knit2slides
logo        : escudoof.gif
biglogo     : marcaderecha.png

--- 
## Comparar grupos.
En estas sesiones vamos a trabajar en comparaciones de medias. En términos generales, trabajaremos con variables dependientes $Y$:
$$ Y \in \mathbb{R} \; | \; \infty^{-} < Y < \infty^{+}$$
y con variables independientes $X$:
$$ X \in \mathbb{Z} \; | \; \infty^{-} < Y < \infty^{+}.$$

Asumimos además que $\mu$ corresponde a la media artimética poblacional y $\sigma^{2}$ a la varianza de la población.


--- .segue bg:royalblue
# Datos para esta clase.

---
## Datos simulados: fumadores
Vamos a simular datos sobre la edad de muerte de un grupo de 35 personas, jun to con optras características relevantes.
```{r}
fumadores<-data.frame(id = 1:36,
                edad_muerte = c(sample(70:90,18,replace = TRUE), sample(60:80, 18, 
                replace = TRUE)),
                fuma = c(rep("No", 18), rep("Sí",18)),
                sexo = sample(c("Hombre", "Mujer"), 36, replace = TRUE))
head(fumadores, 5)
```

---
## Datos simulados: bebedores
Simularemos ahora los datos sobre la cantidad de tragos por semana que bebían 2581 personas antes y después de un experimento en el que se les sometía a un programa de erducación sobrer los efectos del alcohol. Se midió también su editorial preferida de comics.
```{r}
bebedores<-data.frame(id = 1:2581,
                editorial = sample(c("Marvel", "DC"), 2581, replace = TRUE),
                grupo = c(rep("Tratamiento", 1200), rep("Control", 1381)),
                tragos_pre = rpois(2581,10),
                tragos_post = c(rpois(1200, 7), rpois(1381,10)))
head(bebedores,5)
```

---
## Datos simulados para ANOVA.
Se recolectaron datos para 60 usuarios de software estadístico. Se registraron escalas de facilidad de uso, flexibilidad de análisis y actualización de procedimientos.

```{r}
software<-data.frame(id = 1:60,
                     software = c(rep("R", 20), rep("SAS", 20), rep("SPSS", 20)),
                     facilidad = c(sample(10:40, 20, replace = T), 
                        sample(25:65, 20, replace = T), sample(40:80, 20, replace = T)),
                     flexibilidad = c(sample(50:85, 20, replace = T), 
                        sample(30:60, 20, replace = T), sample(10:35, 20, replace = T)),
                     actualizacion = c(sample(50:100, 20, replace = T), 
                        sample(20:60, 20, replace = T), sample(20:60, 20, replace = T)))
```

---
Para comprobar el dataframe creado:
```{r}
str(software)
```

---
## Datos reales: Simce 2016
Leeremos el archivop [simce4_2016.xlsx], que pueden descargar de INFODA. Son los datos reales, para cada establecimiento, de sus puntajes para 4º Básico en Lectura y Matemática, además de otras variables.
```{r}
library(readxl)
simce<-read_excel("./simce4_2016.xlsx")

simce$dependencia<-factor(simce$dependencia, levels = c(1,2,3),
                    labels = c("Municipal", "Particular Subvencionado", "Particular"))

simce$gse<-factor(simce$gse, levels = c(1,2,3,4,5),
                  labels = c("Bajo", "Medio Bajo", "Medio", "Medio Alto", "Alto"))

simce$rural<-factor(simce$rural, levels = c(1,2),
                    labels = c("Urbano", "Rural"))
```

---
Posteriormente, comprobamos las variables recodificadas:
```{r}
head(simce)
```

--- .segue bg:royalblue
# Diferencias de dos medias

--- .segue bg:royalblue
## Muestras independientes.

---
## Supuestos.

### Variable dependiente normalmente distribuida
Asumimos que la variable dependiente tiene una distribución **similar** a la normal en ambos niveles de la variable independiente. A pesar de esto, la prueba T es robusta para desviaciones de la distribución normal, únicamente si se garantiza que:
$$ \frac{n_{mayor}}{n_{menor}} \leq 1,5$$

### Homocedasticidad.
Las varianzas de ambos grupos son iguales. En caso de no cumplirse este supuesto, se pueden hacer algunas correcciones que vienen  incluidas en la función del test.

---
## Error Estándar.
Recordemos que para la variable aleatoria $X$, la **varianza de su distribución de muestreo** equivale a:
$$ \hat{\sigma}^{2}_{\overline{X}} = \frac{\sigma^{2}}{n}$$
De esta forma, la diferencia entre dos grupos tiene el siguiente **error estándar**
$$ \hat{\sigma}_{\overline{X}_{2}- \overline{X}_{1}} =  \sqrt{\hat{\sigma}^{2}_{\overline{X}}} = \sqrt{\frac{\sigma^{2}_{1}}{n_{1}} + \frac{\sigma^{2}_{2}}{n_{2}}}$$
Estas medidas son relevantes para construir los **intervalos de confianza**.

---
## Ejemplo: fumadores
### Verificando supuestos.
Para conocer si una variable distribuye normal, utilizaremos el test *shapiro-wilk*
```{r}
shapiro.test(fumadores$edad_muerte)
```
La variable aparentemente es normal, pero debemos asegurarnos que lo sea para cada **nivel** de la variable [fuma]

---

```{r}
tapply(fumadores$edad_muerte, fumadores$fuma, shapiro.test)
```

---
Si no obtenemos normalidad, podemos verificar el *ratio* entre el $n$ de ambos grupos:
```{r}
length(fumadores$fuma[fumadores$fuma=="Sí"])/length(fumadores$fuma[fumadores$fuma=="No"])
```

### Homocedasticidad.
Para verificar este supuesto, utilizamos la prueba de Bartlett, cuya hipótesis nula es:
$$ H_{0}: \; \sigma^{2}_{fuma} - \sigma^{2}_{no\;  fuma} = 0 $$
```{r}
bartlett.test(fumadores$edad_muerte~fumadores$fuma)
```

---
## T-test
La hipótesis nula es:
$$ H_{0}: \; \overline{Y}_{fuma} - \overline{Y}_{no\;  fuma} = 0 $$
Veamos primero los promedios de edad de muerte para ambos grupos:
```{r}
tapply(fumadores$edad_muerte, fumadores$fuma, mean)
```
Al parecer, la diferencia no es cero.

---
Probemos que esta diferencia efectivamente es distinta de cero.
```{r}
t.test(edad_muerte~fuma, data = fumadores, var.equal=TRUE)
```

---
## Alternativa no-paramétrica.
Si no logramos cumplir el primer supuesto, ya sea porque la variable no distribuye normal, o porquer la razón entre el tamaño de ambos grupos es mayor a 1,5; se puede utilizar una prueba no-paramétrica.

La prueba de Mann Whitney compara **medianas** con la siguiente hipótesis nula:
$$ H_{0}: \; Y_{fuma} - Y_{no\;  fuma} = 0 $$

---
La función en R:

```{r}
wilcox.test(edad_muerte~fuma, data=fumadores)
```

--- .segue bg:royalblue
## Muestras dependientes

---
## Lógica experimental.
Una prueba de diferencia de medias para **muestras dependientes** considera una lógica experimental, dado que compara a cada individuo consigo mismo en un tiempo previo. Considere una variable aleatoria $X$ en un tiempo $t$ (medición final), lo que se estima es la siguiente diferencia.
$$ \overline{X}_{t} - \overline{X}_{t-1} $$
Obviamente, se puede estimar una diferencia con un *lag* mayor a 1, pero como se trata de diferencias de dos medias, siempre se trabajará con dos puntos temporales.

---
## La función en R.
Consideremos el dataframe [bebedores], que simula los resultados de un tratamiento que busca disminuir la cantidad de tragos por semana de un grupo de personas. Debemos asegurarnos que al inicio, los grupos estén balanceados:
```{r}
t.test(tragos_pre~grupo, data = bebedores)
```

---
Noten que acabamos de hacer una prueba de muestras **independientes**, que arrojó que al comienzo del experimento, los grupos están balanceados. Veamos ahora sí en términos generales, existe un efecto del tratamiento en la cantidad de tragos por semana.
```{r}
t.test(bebedores$tragos_post,bebedores$tragos_pre, paired = TRUE)
```

---
Los resultados indican que en promedio, el tratamiento hace que la población **general** disminuya en 1,3 tragos por semana. 

Si se quiere, una interpretación de los resultados que utilice el intervalo de confianza, es que la población general disminuye entre **1,5** y **1,2** tragos por semana.

Podemos ser más específicos, replanteando la hipótesis alternativa, si tenemos evidencia suficiente para postular una hipótesis **direccional**. En este caso:
$$ H_{0}:\; \overline{Y}_{POST} - \overline{Y}_{PRE} = 0$$
$$ H_{0}:\; \overline{Y}_{POST} - \overline{Y}_{PRE} < 0$$

---
Esta hipótesis se ve reflejada en la función:
```{r}
t.test(bebedores$tragos_post, bebedores$tragos_pre, paired = TRUE, alternative = "less")
```
Este resultado indica que la diferencia entre los tragos pre y post es como mínimo 1,2. Dicho de otra forma, en promedio, el tratamiento disminuye **como mínimo en 1,2** tragos por semana.

---
## Alternativa no-paramétrica.
La función es similar que para muestras independientes, sólo que se agrega el argumento *paired*.
```{r}
wilcox.test(bebedores$tragos_post, bebedores$tragos_pre, paired = TRUE)
```
Este resultado muestra una diferencia **estadísticamente significativa** entre la medición pre y la medición post. Como se observa, la conclusión es menos precisa, pero esto se compensa con que las ocasiones en que se aplica esta prueba son mucho más **restrictivas** que cuando se utiliza la alternativa paramétrica.

--- .segue bg:royalblue
# Diferencias entre $k$ medias.

---
## Una idea relevante.
Si queremos comparar los valores promedio de los $k$ niveles de una variable $Y$, **¿por qué no hacemos $\binom{k}{2}$ comparaciones utilizando pruebas T?**

Supongamnos el caso más simple, una variable con tres niveles:
$$ x \in \{x_{1}, x_{2}, x_{3} \}$$

Podríamos hacer las siguientes comparaciones:

* $H_{0}: \; \overline{X}_{1} - \overline{X}_{2} = 0$
* $H_{0}: \; \overline{X}_{2} - \overline{X}_{3} = 0$
* $H_{0}: \; \overline{X}_{1} - \overline{X}_{3} = 0$

---
## El problema dsel enfoque anterior.
Si cada una de estas comparaciones se realiza con un **95%** de confianza; y asumimos que son independientes entre sí, el nivel de confianza de la prueba será:
$$ 0,95 \times 0,95 \times  0,95 = 0,95^3 = 0,857375$$

Por tanto, la probabilidad de cometer un **error tipo I** es:
$$ 1 - 0,95^3 = 0,142625 $$

De esta forma, si hacemos comparaciones múltiples, en lugar de trabajar con un máximo de 5% de rechazar kla hipótesis nula, trabajamos con un 14,26%.

--- 
## Supuestos de la prueba de análisis de varianza.
### Homocedasticidad
Al igual que para dos medias, se puede verificar este supuesto con una prueba de Bartlett.
```{r}
bartlett.test(software$facilidad, software$software)
```

---
### Las distribuciones de la variable dependiente para los $k$ grupos son normales.
```{r}
by(software$facilidad, software$software, shapiro.test)
```

---
## La prueba ANOVA.
Consideremos el mismo ejemplo anterior, cuya hipótesis nula es:
$$H_{0}: \; \overline{Y}_{R} = \overline{Y}_{SAS} = \overline{Y}_{SPSS}$$
Para facilitar el proceso, crearemos un objeto [anova1] con los resultados de la comparación.
```{r}
anova1<-aov(facilidad~software, data = software)

summary(anova1)
```

---
## ¿Dónde están las diferencias?
Se pueden hacer comparaciones múltipes con la siguiente función:
```{r}
TukeyHSD(anova1)
```

---
O bien, se puede observar gráficamente.
```{r}
boxplot(software$facilidad~software$software)
```

--- .segue bg:royalblue
## Cuando no se cumplen los supuestos.

---
## Heterocedasticidad.
En caso de haber obtenido varianzas que no son iguales en la prueba de Bartlett, se puede utilizar la prueba F de Welch.
```{r}
oneway.test(facilidad~software, data = software)
```

----
## Distribución normal de las variables
Si no se cumple este supuesto, podemos usar la prueba no-paramétrica de **Kruskal-Wallis**
```{r}
kruskal.test(facilidad~software, data = software)
```

--- .segue bg:royalblue
# ¿Preguntas?